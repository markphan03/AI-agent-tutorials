{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d800ad24",
   "metadata": {},
   "source": [
    "# LangGraph tutorial ü§ñü§ñü§ñ\n",
    "By the end of this tutorial, you will create a simple LangGraph workflow like this visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa84c0",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71f0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet langchain langchain-ollama langgraph chromadb beautifulsoup4 langchain-community pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee68359",
   "metadata": {},
   "source": [
    "### Get Llama 3.1 model\n",
    "\n",
    "If you don't have `llama3.1` yet, follow this url to download it locally: https://github.com/ollama/ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f9693",
   "metadata": {},
   "source": [
    "## Putting them All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e87a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embd = OllamaEmbeddings(model=\"llama3.1\")\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embd,\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364e8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "10dbbe58-a283-48cb-a4fe-a95427b40a0d",
       "rows": [
        [
         "0",
         "LLM Powered Autonomous Agents | Lil'Log\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLil'Log\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n|\n\n\n\n\n\n\nPosts\n\n\n\n\nArchive\n\n\n\n\nSearch\n\n\n\n\nTags\n\n\n\n\nFAQ"
        ],
        [
         "1",
         "LLM Powered Autonomous Agents\n    \nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n\n\n \n\n\nTable of Contents\n\n\n\nAgent System Overview\n\nComponent One: Planning\n\nTask Decomposition\n\nSelf-Reflection"
        ],
        [
         "2",
         "Component Two: Memory\n\nTypes of Memory\n\nMaximum Inner Product Search (MIPS)\n\n\nComponent Three: Tool Use\n\nCase Studies\n\nScientific Discovery Agent\n\nGenerative Agents Simulation\n\nProof-of-Concept Examples\n\n\nChallenges\n\nCitation\n\nReferences"
        ],
        [
         "3",
         "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating"
        ],
        [
         "4",
         "well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver."
        ],
        [
         "5",
         "Agent System Overview#\nIn a LLM-powered autonomous agent system, LLM functions as the agent‚Äôs brain, complemented by several key components:"
        ],
        [
         "6",
         "Planning"
        ],
        [
         "7",
         "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks."
        ],
        [
         "8",
         "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results."
        ],
        [
         "9",
         "Memory"
        ],
        [
         "10",
         "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn."
        ],
        [
         "11",
         "Long-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval."
        ],
        [
         "12",
         "Tool use"
        ],
        [
         "13",
         "The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and"
        ],
        [
         "14",
         "more."
        ],
        [
         "15",
         "Overview of a LLM-powered autonomous agent system."
        ],
        [
         "16",
         "Component One: Planning#\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\nTask Decomposition#"
        ],
        [
         "17",
         "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to ‚Äúthink step by step‚Äù to utilize more test-time computation to decompose hard tasks into"
        ],
        [
         "18",
         "smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model‚Äôs thinking process."
        ],
        [
         "19",
         "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search"
        ],
        [
         "20",
         "process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote."
        ],
        [
         "21",
         "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human"
        ],
        [
         "22",
         "inputs."
        ],
        [
         "23",
         "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe"
        ],
        [
         "24",
         "the planning problem. In this process, LLM (1) translates the problem into ‚ÄúProblem PDDL‚Äù, then (2) requests a classical planner to generate a PDDL plan based on an existing ‚ÄúDomain PDDL‚Äù, and finally (3) translates the PDDL plan back into natural"
        ],
        [
         "25",
         "language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains."
        ],
        [
         "26",
         "Self-Reflection#"
        ],
        [
         "27",
         "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable."
        ],
        [
         "28",
         "ReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use"
        ],
        [
         "29",
         "Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language."
        ],
        [
         "30",
         "The ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\nThought: ...\nAction: ...\nObservation: ...\n... (Repeated many times)"
        ],
        [
         "31",
         "Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023)."
        ],
        [
         "32",
         "In both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: ‚Ä¶ step is removed."
        ],
        [
         "33",
         "Reflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the"
        ],
        [
         "34",
         "action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the"
        ],
        [
         "35",
         "environment to start a new trial depending on the self-reflection results."
        ],
        [
         "36",
         "Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)"
        ],
        [
         "37",
         "The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence"
        ],
        [
         "38",
         "of consecutive identical actions that lead to the same observation in the environment."
        ],
        [
         "39",
         "Self-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent‚Äôs working memory, up to three, to be"
        ],
        [
         "40",
         "used as context for querying LLM."
        ],
        [
         "41",
         "Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)"
        ],
        [
         "42",
         "Chain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\{(x, y_i , r_i ,"
        ],
        [
         "43",
         "z_i)\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\geq r_{n-1} \\geq"
        ],
        [
         "44",
         "\\dots \\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\tau_h = (x, z_i, y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is finetuned to only predict $y_n$ where conditioned on"
        ],
        [
         "45",
         "the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time."
        ],
        [
         "46",
         "To avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens"
        ],
        [
         "47",
         "during training."
        ],
        [
         "48",
         "The training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset."
        ],
        [
         "49",
         "After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 730
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LLM Powered Autonomous Agents\\n    \\nDate: Jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Component Two: Memory\\n\\nTypes of Memory\\n\\nMa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Building agents with LLM (large language model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well-written copies, stories, essays and progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>[21] Greshake et al. ‚ÄúCompromising Real-World ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>[22] Jain et al. ‚ÄúBaseline Defenses for Advers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>[24] Wei &amp; Zou. ‚ÄúEDA: Easy data augmentation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Nlp\\nLanguage-Model\\nSafety\\nAdversarial Attac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Powered by\\n        Hugo &amp;\\n        PaperMod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\...\n",
       "1    LLM Powered Autonomous Agents\\n    \\nDate: Jun...\n",
       "2    Component Two: Memory\\n\\nTypes of Memory\\n\\nMa...\n",
       "3    Building agents with LLM (large language model...\n",
       "4    well-written copies, stories, essays and progr...\n",
       "..                                                 ...\n",
       "725  [21] Greshake et al. ‚ÄúCompromising Real-World ...\n",
       "726  [22] Jain et al. ‚ÄúBaseline Defenses for Advers...\n",
       "727  [24] Wei & Zou. ‚ÄúEDA: Easy data augmentation t...\n",
       "728  Nlp\\nLanguage-Model\\nSafety\\nAdversarial Attac...\n",
       "729       Powered by\\n        Hugo &\\n        PaperMod\n",
       "\n",
       "[730 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([d.page_content for d in doc_splits], columns=[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c223c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.',\n",
       " 'Level-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user‚Äôs requirement and learn how to use them by reading documentation.',\n",
       " 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.',\n",
       " 'Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are some techniques for prompt engineering?\"\n",
    "documents = retriever.invoke(question)\n",
    "documents = [d.page_content for d in documents]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acfcef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Get the model\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "# Declare the State\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    documents: list\n",
    "    genai_response: str\n",
    "    is_answer_correct: str # pick from [\"yes\", \"no\"]\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    state[\"documents\"] = [d.page_content for d in documents]\n",
    "    return state\n",
    "\n",
    "\n",
    "def genai_executes(state: State):\n",
    "    # `state` contains question\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    template = \"\"\"You are a helpful assistant that answers questions.\n",
    "    Here are some documents to help you answer the question:\n",
    "    {documents}\n",
    "    Please write the answer in 5 sentences\n",
    "    Here is the question:\\n {question} \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    print(\"==================== Original Prompt ====================\")\n",
    "    import pprint\n",
    "    pprint.pprint(template)\n",
    "    # üîç Print the final prompt with variables filled in\n",
    "    formatted_prompt = prompt.format(question=question, documents=documents)\n",
    "\n",
    "    print(\"==================== Prompt Sent to Model ====================\")\n",
    "    import pprint\n",
    "    pprint.pprint(formatted_prompt)\n",
    "    print(\"==============================================================\")\n",
    "\n",
    "\n",
    "    print(\"---GENAI---\")\n",
    "    genai_chain = prompt | model | StrOutputParser()\n",
    "    response = genai_chain.invoke({\"question\": question, \"documents\": state[\"documents\"]})\n",
    "    \n",
    "    # Add response to state dict\n",
    "    state[\"genai_response\"] = response\n",
    "    return state\n",
    "\n",
    "class CorrectnessChecker(BaseModel):\n",
    "        \"\"\"Check if answer is correct or not\"\"\"\n",
    "        is_correct: Literal[\"yes\", \"no\"] = Field(\n",
    "            ...,\n",
    "            description=\"Return 'yes' if the answer is correct. Otherwise, return 'no'\"\n",
    "        ) \n",
    "\n",
    "def correctness_checker_executes(state: State):\n",
    "    # `state` contains question and genai_response\n",
    "    print(\"==============================================================\")\n",
    "    print(\"---CHECK-CORRECT---\")\n",
    "    question = state[\"question\"]\n",
    "    genai_response = state[\"genai_response\"]\n",
    "\n",
    "    # preamble\n",
    "    system_prompt = \"\"\"You are a helpful assistant that determine the correctness of\n",
    "        the GenAI response from a question. Here is the question: \\n {question}\\n\n",
    "        Here is the GenAI response: \\n {genai_response}\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    structured_model = model.with_structured_output(CorrectnessChecker)\n",
    "    \n",
    "    correctness_checker_chain = prompt | structured_model \n",
    "    state[\"is_answer_correct\"] = correctness_checker_chain.invoke({\"question\": question, \"genai_response\": genai_response}).is_correct\n",
    "    return state\n",
    "\n",
    "def is_response_correct(state: State):\n",
    "    return True if state[\"is_answer_correct\"] == \"yes\" else False\n",
    "\n",
    "\n",
    "def create_workflow() -> StateGraph:\n",
    "    workflow = StateGraph(State)\n",
    "\n",
    "    # Add node\n",
    "    workflow.add_node(\"retrieve\", retrieve)\n",
    "    workflow.add_node(\"genai\", genai_executes)\n",
    "    workflow.add_node(\"correctness_checker\", correctness_checker_executes)\n",
    "\n",
    "    # Add edges and conditional edges\n",
    "    workflow.add_edge(START, \"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"genai\")\n",
    "    workflow.add_edge(\"genai\", \"correctness_checker\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"correctness_checker\",\n",
    "        is_response_correct,\n",
    "        {\n",
    "            False: \"genai\",\n",
    "            True: END\n",
    "        }\n",
    "    )\n",
    "    return workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4780e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "'Retrieved Documents:'\n",
      "[ 'Short-term memory: I would consider all the in-context learning (See Prompt '\n",
      "  'Engineering) as utilizing short-term memory of the model to learn.',\n",
      "  'Level-2 examines the ability to retrieve the API. The model needs to search '\n",
      "  'for possible APIs that may solve the user‚Äôs requirement and learn how to '\n",
      "  'use them by reading documentation.',\n",
      "  'Prompt Engineering, also known as In-Context Prompting, refers to methods '\n",
      "  'for how to communicate with LLM to steer its behavior for desired outcomes '\n",
      "  'without updating the model weights. It is an empirical science and the '\n",
      "  'effect of prompt engineering methods can vary a lot among models, thus '\n",
      "  'requiring heavy experimentation and heuristics.\\n'\n",
      "  'This post only focuses on prompt engineering for autoregressive language '\n",
      "  'models, so nothing with Cloze tests, image generation or multimodality '\n",
      "  'models. At its core, the goal of prompt engineering is about alignment and '\n",
      "  'model steerability. Check my previous post on controllable text generation.',\n",
      "  'Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common '\n",
      "  'failure than inefficient planning in AlfWorld. (Image source: Shinn & '\n",
      "  'Labash, 2023)']\n",
      "'\\n---\\n'\n",
      "==================== Original Prompt ====================\n",
      "('You are a helpful assistant that answers questions.\\n'\n",
      " '    Here are some documents to help you answer the question:\\n'\n",
      " '    {documents}\\n'\n",
      " '    Please write the answer in 5 sentences\\n'\n",
      " '    Here is the question:\\n'\n",
      " ' {question} ')\n",
      "==================== Prompt Sent to Model ====================\n",
      "('Human: You are a helpful assistant that answers questions.\\n'\n",
      " '    Here are some documents to help you answer the question:\\n'\n",
      " \"    ['Short-term memory: I would consider all the in-context learning (See \"\n",
      " \"Prompt Engineering) as utilizing short-term memory of the model to learn.', \"\n",
      " \"'Level-2 examines the ability to retrieve the API. The model needs to search \"\n",
      " 'for possible APIs that may solve the user‚Äôs requirement and learn how to use '\n",
      " \"them by reading documentation.', 'Prompt Engineering, also known as \"\n",
      " 'In-Context Prompting, refers to methods for how to communicate with LLM to '\n",
      " 'steer its behavior for desired outcomes without updating the model weights. '\n",
      " 'It is an empirical science and the effect of prompt engineering methods can '\n",
      " 'vary a lot among models, thus requiring heavy experimentation and '\n",
      " 'heuristics.\\\\nThis post only focuses on prompt engineering for '\n",
      " 'autoregressive language models, so nothing with Cloze tests, image '\n",
      " 'generation or multimodality models. At its core, the goal of prompt '\n",
      " 'engineering is about alignment and model steerability. Check my previous '\n",
      " \"post on controllable text generation.', 'Experiments on AlfWorld Env and \"\n",
      " 'HotpotQA. Hallucination is a more common failure than inefficient planning '\n",
      " \"in AlfWorld. (Image source: Shinn & Labash, 2023)']\\n\"\n",
      " '    Please write the answer in 5 sentences\\n'\n",
      " '    Here is the question:\\n'\n",
      " ' What are some techniques for prompt engineering? ')\n",
      "==============================================================\n",
      "---GENAI---\n",
      "\"Node 'genai':\"\n",
      "'GenAI Response:'\n",
      "(\"Based on the provided documents, it appears that there isn't a comprehensive \"\n",
      " 'list of techniques for prompt engineering. However, I can infer that '\n",
      " 'In-Context Prompting is a method used for communicating with Large Language '\n",
      " 'Models (LLMs) to steer their behavior towards desired outcomes without '\n",
      " 'updating the model weights. This involves utilizing short-term memory and '\n",
      " 'in-context learning, as well as reading documentation to learn how to use '\n",
      " \"APIs. It's also mentioned that prompt engineering requires experimentation \"\n",
      " 'and heuristics due to its empirical nature and variability among models. The '\n",
      " 'goal of prompt engineering is about alignment and model steerability, with '\n",
      " 'the aim of achieving controllable text generation.')\n",
      "'\\n---\\n'\n",
      "==============================================================\n",
      "---CHECK-CORRECT---\n",
      "\"Node 'correctness_checker':\"\n",
      "'Correctness Check Result:'\n",
      "'yes'\n",
      "'\\n---\\n'\n",
      "==============================================================\n",
      "'Final Generation:'\n",
      "(\"Based on the provided documents, it appears that there isn't a comprehensive \"\n",
      " 'list of techniques for prompt engineering. However, I can infer that '\n",
      " 'In-Context Prompting is a method used for communicating with Large Language '\n",
      " 'Models (LLMs) to steer their behavior towards desired outcomes without '\n",
      " 'updating the model weights. This involves utilizing short-term memory and '\n",
      " 'in-context learning, as well as reading documentation to learn how to use '\n",
      " \"APIs. It's also mentioned that prompt engineering requires experimentation \"\n",
      " 'and heuristics due to its empirical nature and variability among models. The '\n",
      " 'goal of prompt engineering is about alignment and model steerability, with '\n",
      " 'the aim of achieving controllable text generation.')\n"
     ]
    }
   ],
   "source": [
    "workflow = create_workflow()\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "# Run\n",
    "import pprint\n",
    "inputs = {\"question\": \"What are some techniques for prompt engineering?\"}\n",
    "for output in graph.stream(inputs, {\"recursion_limit\": 100}):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint.pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        if key == \"retrieve\":\n",
    "            pprint.pprint(\"Retrieved Documents:\")\n",
    "            pprint.pprint(value[\"documents\"], indent=2, width=80, depth=None)\n",
    "        elif key == \"genai\":\n",
    "            pprint.pprint(\"GenAI Response:\")\n",
    "            pprint.pprint(value[\"genai_response\"], indent=2, width=80, depth=None)\n",
    "        elif key == \"correctness_checker\":\n",
    "            pprint.pprint(\"Correctness Check Result:\")\n",
    "            pprint.pprint(value[\"is_answer_correct\"], indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "print(\"==============================================================\")\n",
    "pprint.pprint(\"Final Generation:\")\n",
    "pprint.pprint(value[\"genai_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
